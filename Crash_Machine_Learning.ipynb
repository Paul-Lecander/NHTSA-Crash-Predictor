{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34700/996482792.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Import the CRSS connection string.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcrss_conn_string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "# Import the dependencies.\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Import the CRSS connection string.\n",
    "from config import crss_conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONNECT TO THE DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSSR engine.\n",
    "cssr_engine = create_engine(crss_conn_string);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to server.\n",
    "cssr_conn = cssr_engine.connect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create accidents, vehicles, people data frame.\n",
    "avp_df = pd.read_sql(\"SELECT * FROM public.accident_vehicle_person\", cssr_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 10 rows.\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "avp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "avp_df.to_csv('all_gas_no_brakes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe Data\n",
    "avp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode Urban City : 0 = urban, 1 = city\n",
    "avp_df['urbancity'] = avp_df['urbancity'].replace(1,0)\n",
    "avp_df['urbancity'] = avp_df['urbancity'].replace(2,1)\n",
    "avp_df['urbancity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode Month : 1 = Jan, 12 = Dec\n",
    "avp_df['month']= avp_df['month'].replace([1,2,3,4,5,6,7,8,9,10,11,12],['Jan','Feb','Mar','Apr','May',\n",
    "                                                                             'Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n",
    "avp_df['month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode Day of the week 1= Sunday, 7 = Saturday\n",
    "avp_df['day_week']= avp_df['day_week'].replace([1,2,3,4,5,6,7],['Sun','Mon','Tues','Wed','Thus','Fri','Sat'])\n",
    "avp_df['day_week'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode Alcohol - accident level 1= alcohol involved, 2,8,9 =  no alcohol\n",
    "avp_df['alcohol'] = avp_df['alcohol'].replace([1,2,8,9],[1,0,0,0])\n",
    "avp_df['alcohol'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode max severity - accident level 0,8,9 = none, 1,2,5 = minor, 3 = serious, 4,6 = fatal\n",
    "avp_df['max_sev']=avp_df['max_sev'].replace([0,8,9,1,2,5,3,4,6],['none', 'none','none','minor','minor',\n",
    "                                                                 'minor','serious','fatal','fatal'])\n",
    "avp_df['max_sev'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode work zone 0 = no (0), 1,2,3,4 = yes (1)\n",
    "avp_df['wrk_zone'] = avp_df['wrk_zone'].replace([0,1,2,3,4],[0,1,1,1,1])\n",
    "avp_df['wrk_zone'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode lighting conditions 1= daylight, 2,3,6 = dark, 4=dawn 5=dusk, 7,8,9 = other\n",
    "avp_df['lgt_cond']= avp_df['lgt_cond'].replace([1,2,3,6,4,5,7,8,9],['daylight','dark','dark','dark','dawn','dusk',\n",
    "                                                                     'other','other','other'])\n",
    "avp_df['lgt_cond'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode weather 1 = clear 2,3 = rain/sleet/hail, 4,11 = snow, 5 = fog/smoke, 6=windy, 7=blowing dirt, \n",
    "# 10=cloudy, 12=freezing rain, 8, 98, 99 = other\n",
    "avp_df['weather']=avp_df['weather'].replace([1,2,3,4,11,5,6,7,10,12,8,98,99],['clear','rain_sleet','rain_sleet',\n",
    "                                                                              'snow_blowsnow','snow_blowsnow',\n",
    "                                                                              'fog_smoke','windy','blowing_dirt','cloudy',\n",
    "                                                                              'freezing_rain','other','other','other'])\n",
    "avp_df['weather'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avp_df['m_harmname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode most harmful event - vehicle level\n",
    "avp_df['m_harmname'] = avp_df['m_harmname'].replace([\n",
    "   'Motor Vehicle In-Transport',\n",
    "    'Motor Vehicle in Motion Outside the Trafficway',\n",
    "    'Working Motor Vehicle',\n",
    "    \n",
    "    'Parked Motor Vehicle', \n",
    "    \n",
    "    'Pedalcyclist',\n",
    "    'Pedestrian',\n",
    "    'Non-Motorist on Personal Conveyance',\n",
    "    'Ridden Animal or Animal Drawn Conveyance',\n",
    "    'Live Animal',\n",
    "    \n",
    "    'Traffic Sign Support',\n",
    "    'Utility Pole/Light Support',\n",
    "    'Bridge Pier or Support',\n",
    "    'Guardrail End',\n",
    "    'Post, Pole or Other Supports',\n",
    "    'Impact Attenuator/Crash Cushion',\n",
    "    'Fire Hydrant',\n",
    "    'Other Fixed Object',\n",
    "    'Unknown Fixed Object',\n",
    "    'Mail Box',\n",
    "    'Traffic Signal Support',\n",
    "    'Bridge Overhead Structure',\n",
    "    'Building',\n",
    "    \n",
    "    'Bridge Rail (Includes parapet)',\n",
    "    'Curb', \n",
    "    'Guardrail Face',\n",
    "    'Concrete Traffic Barrier',\n",
    "    'Other Traffic Barrier',\n",
    "    'Wall', \n",
    "    'Cable Barrier',\n",
    "    'Fence',\n",
    "    \n",
    "    'Shrubbery',\n",
    "    'Tree (Standing Only)',\n",
    "    'Boulder',\n",
    "    'Snow Bank',\n",
    "    \n",
    "    'Embankment',\n",
    "    'Ditch', \n",
    "    'Ground',\n",
    "    'Culvert',\n",
    "    \n",
    "    'Fire/Explosion',\n",
    "    \n",
    "    'Motor Vehicle In-Transport Strikes or is Struck by Cargo, Persons or Objects Set-in-Motion from/by Another Motor Vehicle In Transport',\n",
    "    'Object That Had Fallen From Motor Vehicle In-Transport',\n",
    "    'Unknown Object Not Fixed',\n",
    "    'Thrown or Falling Object',\n",
    "    'Other Object (not fixed)',\n",
    "    \n",
    "    'Immersion or Partial Immersion',\n",
    "    \n",
    "    'Reported as Unknown',\n",
    "    'Harmful Event, Details Not Reported',\n",
    "    \n",
    "    'Pavement Surface Irregularity (Ruts, Potholes, Grates, etc.)',\n",
    "    'Jackknife (harmful to this vehicle)',\n",
    "    'Other Non-Collision',\n",
    "    'Cargo/Equipment Loss, Shift, or Damage [harmful]',\n",
    "    'Rollover/Overturn',\n",
    "    \n",
    "    'Injured In Vehicle (Non-Collision)',\n",
    "    'Fell/Jumped from Vehicle', \n",
    "    \n",
    "     'Railway Vehicle',\n",
    "    'Road Vehicle on Rails'    \n",
    "],\n",
    "[\n",
    "    'harm_moving_veh',\n",
    "    'harm_moving_veh',\n",
    "    'harm_moving_veh',\n",
    "    \n",
    "    'harm_parked_veh',\n",
    "    \n",
    "    'harm_ped_animal',\n",
    "    'harm_ped_animal',\n",
    "    'harm_ped_animal',\n",
    "    'harm_ped_animal',\n",
    "    'harm_ped_animal',\n",
    "    \n",
    "    'harm_fixed_manmade',\n",
    "    'harm_fixed_manmade',\n",
    "    'harm_fixed_manmade',\n",
    "    'harm_fixed_manmade',\n",
    "    'harm_fixed_manmade',\n",
    "    'harm_fixed_manmade',\n",
    "    'harm_fixed_manmade',\n",
    "    'harm_fixed_manmade',\n",
    "    'harm_fixed_manmade',\n",
    "    'harm_fixed_manmade',\n",
    "    'harm_fixed_manmade',\n",
    "    'harm_fixed_manmade',\n",
    "    'harm_fixed_manmade',\n",
    "    \n",
    "    'harm_barrier',\n",
    "    'harm_barrier',\n",
    "    'harm_barrier',\n",
    "    'harm_barrier',\n",
    "    'harm_barrier',\n",
    "    'harm_barrier',\n",
    "    'harm_barrier',\n",
    "    'harm_barrier',\n",
    "    \n",
    "    'harm_nat_object',\n",
    "    'harm_nat_object',\n",
    "    'harm_nat_object',\n",
    "    'harm_nat_object',\n",
    "    \n",
    "    'harm_terrain',\n",
    "    'harm_terrain',\n",
    "    'harm_terrain',\n",
    "    'harm_terrain',\n",
    "    \n",
    "    'harm_fire',\n",
    "    \n",
    "    'harm_object',\n",
    "    'harm_object',\n",
    "    'harm_object',\n",
    "    'harm_object',\n",
    "    'harm_object',\n",
    "    \n",
    "    'harm_water',\n",
    "    \n",
    "    'harm_unknown',\n",
    "    'harm_unknown',\n",
    "    \n",
    "    'harm_lost_control',\n",
    "    'harm_lost_control',\n",
    "    'harm_lost_control',\n",
    "    'harm_lost_control',\n",
    "    'harm_lost_control',\n",
    "    \n",
    "    'harm_injury_fallout',\n",
    "    'harm_injury_fallout',\n",
    "    \n",
    "    'harm_train',\n",
    "    'harm_train'    \n",
    "])\n",
    "avp_df['m_harmname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avp_df['makename'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode vehicle make as make_country\n",
    "avp_df['make_country'] = avp_df['makename'].replace([\n",
    "    'Toyota',\n",
    "    'Honda',\n",
    "    'Subaru',\n",
    "    'Nissan/Datsun',\n",
    "    'Acura',\n",
    "    'Suzuki',\n",
    "    'Lexus',\n",
    "    'Mazda', \n",
    "    'Mitsubishi', \n",
    "    'Infiniti', \n",
    "    'Isuzu',\n",
    "    'Scion',\n",
    "    \n",
    "    'KIA',\n",
    "    'Daewoo',\n",
    "    'Hyundai',\n",
    "    \n",
    "    'Chevrolet', \n",
    "    'Ford',\n",
    "    'Pontiac',\n",
    "    'Cadillac',\n",
    "    'Dodge', \n",
    "    'Chrysler', \n",
    "    'GMC',\n",
    "    'Jeep / Kaiser-Jeep / Willys- Jeep', \n",
    "    'Buick / Opel',\n",
    "    'Other Domestic Manufacturers', \n",
    "    'Lincoln',\n",
    "    'Oldsmobile', \n",
    "    'Mercury',\n",
    "    'Plymouth', \n",
    "    'Eagle', \n",
    "    'American Motors',\n",
    "    'Saturn',\n",
    "    \n",
    "    'Freightliner', \n",
    "    'AM General', \n",
    "    'International Harvester/Navistar',\n",
    "    'Peterbilt',\n",
    "    'Mack',\n",
    "    'Kenworth',\n",
    "    'Thomas Built', \n",
    "    'Bluebird',\n",
    "    'White/Autocar White/GMC',\n",
    "    'Gillig', \n",
    "    'MCI',\n",
    "    'Grumman',\n",
    "    \n",
    "    'Mercedes-Benz',\n",
    "    'Volkswagen',\n",
    "    'Audi',\n",
    "    'BMW', \n",
    "    'Smart',\n",
    "    'Porsche',\n",
    "    \n",
    "    'Victory',\n",
    "    \n",
    "    'Volvo',\n",
    "    'Saab', \n",
    "    \n",
    "    'Ducati', \n",
    "    'Harley-Davidson', \n",
    "    'Yamaha', \n",
    "    'Kawasaki',\n",
    "    'Moto-Guzzi',\n",
    "    \n",
    "    'Jaguar',\n",
    "    'Land Rover',\n",
    "    'Triumph', \n",
    "    \n",
    "    'Alfa Romeo',\n",
    "    'Fiat',\n",
    "    \n",
    "    'Other Import',\n",
    "    'Other Make',\n",
    "    'Unknown Make',\n",
    "    'Not Reported',\n",
    "],\n",
    "[\n",
    "    'make_Japan',\n",
    "    'make_Japan',\n",
    "    'make_Japan',\n",
    "    'make_Japan',\n",
    "    'make_Japan',\n",
    "    'make_Japan',\n",
    "    'make_Japan',\n",
    "    'make_Japan',\n",
    "    'make_Japan',\n",
    "    'make_Japan',\n",
    "    'make_Japan',\n",
    "    'make_Japan',\n",
    "    \n",
    "    'make_Korea',\n",
    "    'make_Korea',\n",
    "    'make_Korea',\n",
    "    \n",
    "    'make_US',\n",
    "    'make_US',\n",
    "    'make_US',\n",
    "    'make_US',\n",
    "    'make_US',\n",
    "    'make_US',\n",
    "    'make_US',\n",
    "    'make_US',\n",
    "    'make_US',\n",
    "    'make_US',\n",
    "    'make_US',\n",
    "    'make_US',\n",
    "    'make_US',\n",
    "    'make_US',\n",
    "    'make_US',\n",
    "    'make_US',\n",
    "    'make_US',\n",
    "    \n",
    "    'make_US_truck',\n",
    "    'make_US_truck',\n",
    "    'make_US_truck',\n",
    "    'make_US_truck',\n",
    "    'make_US_truck',\n",
    "    'make_US_truck',\n",
    "    'make_US_truck',\n",
    "    'make_US_truck',\n",
    "    'make_US_truck',\n",
    "    'make_US_truck',\n",
    "    'make_US_truck',\n",
    "    'make_US_truck',\n",
    "    \n",
    "    'make_Germany',\n",
    "    'make_Germany',\n",
    "    'make_Germany',\n",
    "    'make_Germany',\n",
    "    'make_Germany',\n",
    "    'make_Germany',\n",
    "    \n",
    "    'make_China',\n",
    "    \n",
    "    'make_Sweden',\n",
    "    'make_Sweden',\n",
    "    \n",
    "    'make_motorcycle',\n",
    "    'make_motorcycle',\n",
    "    'make_motorcycle',\n",
    "    'make_motorcycle',\n",
    "    'make_motorcycle',\n",
    "    \n",
    "    'make_England',\n",
    "    'make_England',\n",
    "    'make_England',\n",
    "    \n",
    "    'make_Italy',\n",
    "    'make_Italy',\n",
    "    \n",
    "    'make_other',\n",
    "    'make_other',\n",
    "    'make_other',\n",
    "    'make_other',    \n",
    "])\n",
    "avp_df['make_country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode tow_vehname - towing a vehichle 0 = no, 1 = yes\n",
    "avp_df['tow_vehname']=avp_df['tow_vehname'].replace([\n",
    "    'No Trailing Units',\n",
    "    'One Trailing Unit',\n",
    "    'Unknown',\n",
    "    'Two Trailing Units',\n",
    "    'Vehicle Towing Another Motor Vehicle - Non-Fixed Linkage',\n",
    "    'Three or More Trailing Units',\n",
    "    'Vehicle Towing Another Motor Vehicle - Fixed Linkage',\n",
    "    'Yes, Number of Trailing Units Unknown'\n",
    "],\n",
    "[0,1,1,1,1,1,1,1])\n",
    "avp_df['tow_vehname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine median speed for imputing for unknown travel Speed\n",
    "avp_df['trav_speed_temp'] = avp_df['trav_speed']\n",
    "avp_df['trav_speed_temp'] = avp_df['trav_speed_temp'].replace([997,998,999],[np.NaN,np.NaN,np.NaN])\n",
    "avp_df['trav_speed_temp'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace unknown travel speed with median travel speed \n",
    "avp_df['trav_speed']=avp_df['trav_speed'].replace([997,998,999],[155,23,23])\n",
    "avp_df['trav_speed'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode deformedname\n",
    "avp_df['deformedname']=avp_df['deformedname'].replace([\n",
    "    'Not Reported',\n",
    "    'Reported as Unknown'\n",
    "],\n",
    "[\n",
    "    'Minor Damage',\n",
    "    'Minor Damage'\n",
    "])\n",
    "avp_df['deformedname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode towed Name 0 = no 1 = yes\n",
    "avp_df['towedname']=avp_df['towedname'].replace([\n",
    "    'Towed Due to Disabling Damage',\n",
    "    'Not Towed',\n",
    "    'Towed Not Due to Disabling Damage',\n",
    "    'Towed, Unknown Reason',\n",
    "    'Not Reported',\n",
    "    'Towed But Not Due to Disabling Damage',\n",
    "    'Reported as Unknown'\n",
    "],[1,0,1,1,0,1,0])\n",
    "avp_df['towedname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avp_df['speedrelname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode speed related 0 = n 1 = y\n",
    "avp_df['speedrelname']=avp_df['speedrelname'].replace([\n",
    "    'No', \n",
    "    'Yes, Too Fast for Conditions',\n",
    "    'Reported as Unknown',\n",
    "    'Yes, Exceeded Speed Limit',\n",
    "    'Yes, Specifics Unknown',\n",
    "    'No Driver Present/Unknown if Driver Present', \n",
    "    'Yes, Racing'\n",
    "],[0,1,0,1,1,0,1])\n",
    "avp_df['speedrelname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avp_df['vtrafwayname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode traffic way name \n",
    "avp_df['vtrafwayname']=avp_df['vtrafwayname'].replace([\n",
    "    'Two-Way, Divided, Unprotected Median',\n",
    "    'Not Reported',\n",
    "    'Two-Way,  Divided, Positive  Median Barrier',\n",
    "    'Two-Way, Not Divided',\n",
    "    'Two-Way, Not Divided With a Continuous Left-Turn Lane',\n",
    "    'Non-Trafficway or Driveway Access',\n",
    "    'Entrance/Exit Ramp',\n",
    "    'One-Way Trafficway', \n",
    "    'Reported as Unknown'\n",
    "],\n",
    "[\n",
    "    'Two_way_div_med_nobar',\n",
    "    'Two_way',\n",
    "    'Two_way_div_med_bar',\n",
    "    'Two_way',\n",
    "    'Two-way',\n",
    "    'Parking_lot_driveway',\n",
    "    'Exit_on_ramp',\n",
    "    'One-way',\n",
    "    'Two-way'\n",
    "])\n",
    "avp_df['vtrafwayname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avp_df['vspd_lim'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode speed limits (impute with the mode = 45)\n",
    "avp_df['vspd_lim']=avp_df['vspd_lim'].replace([98,99],[45,45])\n",
    "avp_df['vspd_lim'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avp_df['bdytyp_imname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode body type\n",
    "avp_df['bdytyp_imname']=avp_df['bdytyp_imname'].replace([\n",
    "    '4-door sedan, hardtop',\n",
    "    '5-door/4-door hatchback', \n",
    "    'Sedan/Hardtop, number of doors unknown', \n",
    "    'Hatchback, number of doors unknown',\n",
    "    'Auto-based pickup (includes E1 Camino, Caballero, Ranchero, SSR, G8-ST, Subaru Brat, Rabbit Pickup)',\n",
    "    'Large Limousine-more than four side doors or stretched chassis',\n",
    "    'Auto-based panel (cargo station wagon, auto-based ambulance or hearse)',\n",
    "    'Station Wagon (excluding van and truck based)',\n",
    "    'Other or Unknown automobile type',\n",
    "    'Unknown body type', \n",
    "    'Not Reported',\n",
    "    \n",
    "    '2-door sedan,hardtop,coupe',\n",
    "    '3-door/2-door hatchback',\n",
    "    '3-door coupe',\n",
    "    \n",
    "    'Convertible(excludes sun-roof,t-bar)',\n",
    "    \n",
    "    'Light Pickup',\n",
    "    'Unknown light truck type', \n",
    "    'Unknown (pickup style) light conventional truck type',\n",
    "    'Unknown light vehicle type (automobile,utility vehicle, van, or light truck)',\n",
    "    'Other light conventional truck type',\n",
    "    'Compact Utility (Utility Vehicle Categories Small and Midsize)', \n",
    "    'Cab Chassis Based (includes Rescue Vehicle, Light Stake, Dump, and Tow Truck)',\n",
    "    \n",
    "    'Minivan (Chrysler Town and Country, Caravan, Grand Caravan, Voyager, Voyager, Honda-Odyssey, ...)',\n",
    "    'Large Van-Includes van-based buses (B150-B350, Sportsman, Royal Maxiwagon, Ram, Tradesman,...)',\n",
    "    'Van-Based Bus GVWR greater than 10,000 lbs.', \n",
    "    'Unknown van type',\n",
    "    'Step van (GVWR greater than 10,000 lbs.)',\n",
    "    'Other van type (Hi-Cube Van, Kary)', \n",
    "    'Step-van or walk-in van (GVWR less than or equal to 10,000 lbs.)',\n",
    "    \n",
    "    'Large utility (ANSI D16.1 Utility Vehicle Categories and Full Size and Large)',\n",
    "    'Medium/heavy Pickup (GVWR greater than 10,000 lbs.)',\n",
    "    'Utility Vehicle, Unknown body type', \n",
    "    'Utility station wagon (includes suburban limousines, Suburban, Travellall, Grand Wagoneer)',\n",
    "    'Unknown truck type (light/medium/heavy)',\n",
    "    \n",
    "    'Truck-tractor (Cab only, or with any number of trailing unit; any weight)',\n",
    "    'Single-unit straight truck or Cab-Chassis (GVWR range 19,501 to 26,000 lbs.)',\n",
    "    'Single-unit straight truck or Cab-Chassis (GVWR unknown)',\n",
    "    'Unknown medium/heavy truck type', \n",
    "    'Single-unit straight truck or Cab-Chassis (GVWR range 10,001 to 19,500 lbs.)',\n",
    "    'Single-unit straight truck or Cab-Chassis (GVWR greater than 26,000 lbs.)',\n",
    "    'Unknown if single-unit or combination unit Medium Truck (GVWR range 10,001 lbs. to 26,000 lbs.)',\n",
    "    'Unknown if single-unit or combination unit Heavy Truck (GVWR greater than 26,000 lbs.)',\n",
    "    \n",
    "    'Two Wheel Motorcycle (excluding motor scooters)',\n",
    "    'Motor Scooter',\n",
    "    'Moped or motorized bicycle',\n",
    "    'Unknown motored cycle type',\n",
    "    'Off-road Motorcycle', \n",
    "    'Unenclosed Three Wheel Motorcycle / Unenclosed Autocycle (1 Rear Wheel)',\n",
    "    'Three-wheel Motorcycle (2 Rear Wheels)',\n",
    "    'Other motored cycle type (mini-bikes, pocket motorcycles pocket bikes)',\n",
    "    'Unknown Three Wheel Motorcycle Type',\n",
    "    \n",
    "    'School Bus',\n",
    "    'Transit Bus (City Bus)',\n",
    "    'Other Bus Type', \n",
    "    'Unknown Bus Type',\n",
    "    'Cross Country/Intercity Bus',\n",
    "    \n",
    "    'Construction equipment other than trucks (includes graders)',  \n",
    "    'Farm equipment other than trucks',\n",
    "    \n",
    "    'Medium/heavy truck based motorhome',\n",
    "    'Medium/Heavy Vehicle Based Motor Home',\n",
    "    'Camper or motorhome, unknown truck type',\n",
    "    'Light Vehicle Based Motor Home (chassis mounted)',\n",
    "    'Light Truck Based Motorhome (Chassis Mounted)',\n",
    "    \n",
    "    'Recreational Off-Highway Vehicle',\n",
    "    'Other vehicle type (includes go-cart, fork-lift, city street sweeper dunes/swamp buggy)',\n",
    "    'Low Speed Vehicle (LSV) / Neighborhood Electric Vehicle (NEV)',\n",
    "    'ATV/ATC [All-Terrain Cycle]',\n",
    "    'Golf Cart',\n",
    "     \n",
    "     'Snowmobile'\n",
    "    \n",
    "],[\n",
    "    '4_door_sedan',\n",
    "    '4_door_sedan',\n",
    "    '4_door_sedan',\n",
    "    '4_door_sedan',\n",
    "    '4_door_sedan',\n",
    "    '4_door_sedan',\n",
    "    '4_door_sedan',\n",
    "    '4_door_sedan',\n",
    "    '4_door_sedan',\n",
    "    '4_door_sedan',\n",
    "    '4_door_sedan',\n",
    "    \n",
    "    '2_door_sedan',\n",
    "    '2_door_sedan',\n",
    "    '2_door_sedan',\n",
    "    \n",
    "    'Convertable',\n",
    "    \n",
    "    'Small_SUV_light_truck',\n",
    "    'Small_SUV_light_truck',\n",
    "    'Small_SUV_light_truck',\n",
    "    'Small_SUV_light_truck',\n",
    "    'Small_SUV_light_truck',\n",
    "    'Small_SUV_light_truck',\n",
    "    'Small_SUV_light_truck',\n",
    "    \n",
    "    'Van',\n",
    "    'Van',\n",
    "    'Van',\n",
    "    'Van',\n",
    "    'Van',\n",
    "    'Van',\n",
    "    'Van',\n",
    "    \n",
    "    'Large_SUV',\n",
    "    'Large_SUV',\n",
    "    'Large_SUV',\n",
    "    'Large_SUV',\n",
    "    'Large_SUV',\n",
    "    \n",
    "    'Truck',\n",
    "    'Truck',\n",
    "    'Truck',\n",
    "    'Truck',\n",
    "    'Truck',\n",
    "    'Truck',\n",
    "    'Truck',\n",
    "    'Truck',\n",
    "    \n",
    "    'Motorcylcle_trike',\n",
    "    'Motorcylcle_trike',\n",
    "    'Motorcylcle_trike',\n",
    "    'Motorcylcle_trike',\n",
    "    'Motorcylcle_trike',\n",
    "    'Motorcylcle_trike',\n",
    "    'Motorcylcle_trike',\n",
    "    'Motorcylcle_trike',\n",
    "    'Motorcylcle_trike',\n",
    "    \n",
    "    'Bus',\n",
    "    'Bus',\n",
    "    'Bus',\n",
    "    'Bus',\n",
    "    'Bus',\n",
    "    \n",
    "    'Construction_farm_equip',\n",
    "    'Construction_farm_equip',\n",
    "    \n",
    "    'Motorhome_RV',\n",
    "    'Motorhome_RV',\n",
    "    'Motorhome_RV',\n",
    "    'Motorhome_RV',\n",
    "    'Motorhome_RV',\n",
    "    \n",
    "    'ATV_rec_vehicle',\n",
    "    'ATV_rec_vehicle',\n",
    "    'ATV_rec_vehicle',\n",
    "    'ATV_rec_vehicle',\n",
    "    'ATV_rec_vehicle',\n",
    "    \n",
    "     'Snowmobile',\n",
    "    \n",
    "])\n",
    "avp_df['bdytyp_imname'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avp_df['p_crash1name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode prior to crash movement: some not binned. unknowns binned with going straight\n",
    "avp_df['p_crash1name'] = avp_df['p_crash1name'].replace([\n",
    "    'Going Straight', \n",
    "    'Other(specify:)',\n",
    "    'Unknown', \n",
    "    'No Driver Present / Unknown if Driver Present',\n",
    "        \n",
    "    'Decelerating in Road',\n",
    "    'Stopped in Roadway',\n",
    "    'Backing Up (other than for Parking Position)',\n",
    "    \n",
    "    'Starting in Road',\n",
    "    'Accelerating in Road', \n",
    "    \n",
    "    'Disabled or Parked in Travel lane', \n",
    "    'Entering a Parking Position',\n",
    "    'Leaving a Parking Position',\n",
    "     \n",
    "]\n",
    ",[\n",
    "    'Going straight',\n",
    "    'Going straight',\n",
    "    'Going straight',\n",
    "    'Going straight',\n",
    "    \n",
    "    'Stopping_backup',\n",
    "    'Stopping_backup',\n",
    "    'Stopping_backup',\n",
    "    \n",
    "    'Start on road',\n",
    "    'Start on road',\n",
    "    \n",
    "    'Diasbled_parked',\n",
    "    'Diasbled_parked',\n",
    "    'Diasbled_parked',\n",
    "])\n",
    "avp_df['p_crash1name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode restrictive device\n",
    "avp_df['rest_usename'] = avp_df['rest_usename'].replace([\n",
    "    'Shoulder and Lap Belt Used',\n",
    "    'Shoulder Belt Only Used', \n",
    "    'Other',\n",
    "    'Restraint Used - Type Unknown',\n",
    "    'Lap Belt Only Used',\n",
    "    'Reported as Unknown',\n",
    "    'Not Reported',\n",
    "    \n",
    "    'None Used/Not Applicable', \n",
    "\n",
    "    'Child Restraint Type Unknown', \n",
    "    'Booster Seat', \n",
    "    'Child Restraint System - Forward Facing',\n",
    "    'Child Restraint System  - Rear Facing',\n",
    "    'Child Restraint System - Rear Facing',\n",
    "    \n",
    "    'Racing-Style Harness Used'\n",
    "    \n",
    "   \n",
    "],[\n",
    "    'Seatbelt',\n",
    "    'Seatbelt',\n",
    "    'Seatbelt',\n",
    "    'Seatbelt',\n",
    "    'Seatbelt',\n",
    "    'Seatbelt',\n",
    "    'Seatbelt',\n",
    "    \n",
    "    'No_seatbelt',\n",
    "    \n",
    "    'Child_restraint',\n",
    "    'Child_restraint',\n",
    "    'Child_restraint',\n",
    "    'Child_restraint',\n",
    "    'Child_restraint',\n",
    "    \n",
    "    'Harness'\n",
    "])\n",
    "\n",
    "avp_df['rest_usename'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode retrain misuse 0 = no, 1 = yes\n",
    "avp_df['rest_misname'] = avp_df['rest_misname'].replace([\n",
    "    'No Indication of Mis-Use', \n",
    "    'None Used/Not Applicable',\n",
    "    'Yes, Indication of Mis-Use'\n",
    "],[0,0,1])\n",
    "avp_df['rest_misname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode helmet wear 0= no, 1=yes\n",
    "avp_df['helm_usename']=avp_df['helm_usename'].replace([\n",
    "    'Not Applicable',\n",
    "    'Helmet, Other than DOT-Compliant Motorcycle Helmet',\n",
    "    'Helmet, Unknown if DOT-Compliant', \n",
    "    'No Helmet', \n",
    "    'Not Reported',\n",
    "    'DOT-Compliant Motorcycle Helmet',\n",
    "    'Reported as Unknown if Helmet Worn'\n",
    "],[0,1,1,0,0,1,0])\n",
    "avp_df['helm_usename'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode helmet misuse 0 = no 1 = yes\n",
    "avp_df['helm_misname']=avp_df['helm_misname'].replace([\n",
    "    'None Used/Not Applicable', \n",
    "    'No Indication of Mis-Use',\n",
    "    'Yes, Indication of Mis-Use'\n",
    "],[0,0,1])\n",
    "avp_df['helm_misname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode police reported drinking 0 = no 1 = yes\n",
    "avp_df['drinkingname'] = avp_df['drinkingname'].replace([\n",
    "    'No (Alcohol Not Involved)', \n",
    "    'Not Reported', \n",
    "    'Reported as Unknown',\n",
    "    'Yes (Alcohol Involved)'\n",
    "],[0,0,0,1])\n",
    "avp_df['drinkingname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avp_df['alc_resname'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avp_df['alc_resname_08']=avp_df['alc_resname'].replace([\n",
    "    \n",
    "    'Test Not Given', 'Not Reported', 'Reported as Unknown if Tested',\n",
    "       'AC Test Performed, Results Unknown', '0.220 % BAC', '0.000 % BAC',\n",
    "       '0.070 % BAC', '0.176 % BAC', '0.200 % BAC', '0.080 % BAC',\n",
    "       '0.244 % BAC', '0.170 % BAC', '0.020 % BAC', '0.125 % BAC',\n",
    "       '0.216 % BAC', '0.140 % BAC', '0.090 % BAC', '0.190 % BAC',\n",
    "       '0.230 % BAC', '0.150 % BAC',\n",
    "       'Positive Reading with No Actual Value', '0.172 % BAC',\n",
    "       '0.160 % BAC', '0.187 % BAC', '0.100 % BAC', '0.110 % BAC',\n",
    "       '0.181 % BAC', '0.157 % BAC', '0.210 % BAC', '0.158 % BAC',\n",
    "       '0.119 % BAC', '0.180 % BAC', '0.189 % BAC', '0.130 % BAC',\n",
    "       '0.030 % BAC', '0.208 % BAC', '0.245 % BAC', '0.144 % BAC',\n",
    "       '0.121 % BAC', '0.280 % BAC', '0.195 % BAC', '0.194 % BAC',\n",
    "       '0.017 % BAC', '0.011 % BAC', '0.050 % BAC', '0.076 % BAC',\n",
    "       '0.116 % BAC', '0.060 % BAC', '0.072 % BAC', '0.221 % BAC',\n",
    "       '0.193 % BAC', '0.296 % BAC', '0.161 % BAC', '0.255 % BAC',\n",
    "       '0.075 % BAC', '0.155 % BAC', '0.229 % BAC', '0.214 % BAC',\n",
    "       '0.152 % BAC', '0.250 % BAC', '.94 % or Greater', '0.238 % BAC',\n",
    "       '0.123 % BAC', '0.310 % BAC', '0.014 % BAC', '0.275 % BAC',\n",
    "       '0.290 % BAC', '0.188 % BAC', '0.137 % BAC', '0.114 % BAC',\n",
    "       '0.040 % BAC', '0.212 % BAC', '0.078 % BAC', '0.184 % BAC',\n",
    "       '0.375 % BAC', '0.178 % BAC', '0.088 % BAC', '0.165 % BAC',\n",
    "       '0.115 % BAC', '0.209 % BAC', '0.300 % BAC', '0.168 % BAC',\n",
    "       '0.132 % BAC', '0.260 % BAC', '0.318 % BAC', '0.185 % BAC',\n",
    "       '0.286 % BAC', '0.173 % BAC', '0.077 % BAC', '0.186 % BAC',\n",
    "       '0.120 % BAC', '0.167 % BAC', '0.162 % BAC', '0.111 % BAC',\n",
    "       '0.129 % BAC', '0.287 % BAC', '0.081 % BAC', '0.302 % BAC',\n",
    "       '0.094 % BAC', '0.240 % BAC', '0.135 % BAC', '0.142 % BAC',\n",
    "       '0.131 % BAC', '0.148 % BAC', '0.128 % BAC', '0.309 % BAC',\n",
    "       '0.026 % BAC', '0.159 % BAC', '0.196 % BAC', '0.191 % BAC',\n",
    "       '0.151 % BAC', '0.270 % BAC', '0.108 % BAC', '0.105 % BAC',\n",
    "       '0.204 % BAC', '0.016 % BAC', '0.057 % BAC', '0.109 % BAC',\n",
    "       '0.093 % BAC', '0.113 % BAC', '0.307 % BAC', '0.085 % BAC',\n",
    "       '0.008 % BAC', '0.164 % BAC', '0.269 % BAC', '0.320 % BAC',\n",
    "       '0.138 % BAC', '0.146 % BAC', '0.062 % BAC', '0.083 % BAC',\n",
    "       '0.177 % BAC', '0.247 % BAC', '0.175 % BAC', '0.223 % BAC',\n",
    "       '0.102 % BAC', '0.028 % BAC', '0.222 % BAC', '0.126 % BAC',\n",
    "       '0.228 % BAC', '0.336 % BAC', '0.920 % BAC', '0.239 % BAC',\n",
    "       '0.232 % BAC', '0.201 % BAC', '0.281 % BAC', '0.001 % BAC',\n",
    "       '0.285 % BAC', '0.010 % BAC', '0.197 % BAC', '0.249 % BAC',\n",
    "       '0.101 % BAC', '0.361 % BAC', '0.395 % BAC', '0.163 % BAC',\n",
    "       '0.096 % BAC', '0.382 % BAC', '0.271 % BAC', '0.350 % BAC',\n",
    "       '0.182 % BAC', '0.047 % BAC', '0.211 % BAC', '0.154 % BAC',\n",
    "       '0.166 % BAC', '0.053 % BAC', '0.042 % BAC', '0.218 % BAC',\n",
    "       '0.192 % BAC', '0.215 % BAC', '0.004 % BAC', '0.174 % BAC',\n",
    "       '0.231 % BAC', '0.226 % BAC', '0.227 % BAC', '0.099 % BAC',\n",
    "       '0.139 % BAC', '0.082 % BAC', '0.124 % BAC', '0.002 % BAC',\n",
    "       '0.031 % BAC', '0.272 % BAC', '0.213 % BAC', '0.058 % BAC',\n",
    "       '0.045 % BAC', '0.262 % BAC', '0.198 % BAC', '0.378 % BAC',\n",
    "       '0.224 % BAC', '0.041 % BAC', '0.390 % BAC', '0.112 % BAC',\n",
    "       '0.117 % BAC', '0.205 % BAC', '0.305 % BAC', '0.298 % BAC',\n",
    "       '0.179 % BAC', '0.289 % BAC', '0.242 % BAC', '0.012 % BAC',\n",
    "       '0.147 % BAC', '0.243 % BAC', '0.248 % BAC', '0.106 % BAC',\n",
    "       '0.234 % BAC', '0.141 % BAC', '0.274 % BAC', '0.143 % BAC',\n",
    "       '0.256 % BAC', '0.145 % BAC', '0.006 % BAC', '0.202 % BAC',\n",
    "       '0.207 % BAC', '0.054 % BAC', '0.380 % BAC', '0.068 % BAC',\n",
    "       '0.067 % BAC', '0.384 % BAC', '0.027 % BAC', '0.253 % BAC',\n",
    "       '0.156 % BAC', '0.292 % BAC', '0.136 % BAC', '0.254 % BAC',\n",
    "       '0.322 % BAC', '0.206 % BAC', '0.237 % BAC', '0.600 % BAC',\n",
    "       '0.252 % BAC', '0.095 % BAC', '0.340 % BAC', '0.048 % BAC',\n",
    "       '0.153 % BAC', '0.294 % BAC', '0.337 % BAC', '0.091 % BAC',\n",
    "       '0.233 % BAC', '0.241 % BAC', '0.043 % BAC', '0.171 % BAC',\n",
    "       '0.023 % BAC', '0.334 % BAC', '0.520 % BAC', '0.007 % BAC',\n",
    "       '0.069 % BAC', '0.059 % BAC', '0.104 % BAC', '0.079 % BAC',\n",
    "       '0.268 % BAC', '0.013 % BAC', '0.107 % BAC', '0.236 % BAC',\n",
    "       '0.217 % BAC', '0.066 % BAC', '0.098 % BAC', '0.203 % BAC',\n",
    "       '0.251 % BAC', '0.003 % BAC', '0.308 % BAC', '0.278 % BAC',\n",
    "       '0.246 % BAC', '0.064 % BAC', '0.235 % BAC', '0.086 % BAC',\n",
    "       '0.061 % BAC', '0.259 % BAC', '0.169 % BAC'\n",
    "],[\n",
    "   0,0,0,\n",
    "    0,1,0,\n",
    "    0,1,1,1,\n",
    "    1,1,0,1,\n",
    "    1,1,1,1,\n",
    "    1,1,\n",
    "    0,1,\n",
    "    1,1,1,1,\n",
    "    1,1,1,1,\n",
    "    1,1,1,1,\n",
    "    0,1,1,1,\n",
    "    1,1,1,1,\n",
    "    0,0,0,0,\n",
    "    1,0,0,1,\n",
    "    1,1,1,1,\n",
    "    0,1,1,1,\n",
    "    1,1,1,1,\n",
    "    1,1,0,1,\n",
    "    1,1,1,1,\n",
    "    0,1,0,1,\n",
    "    1,1,1,1,\n",
    "    1,1,1,1,\n",
    "    1,1,1,1,\n",
    "    1,1,0,1,\n",
    "    1,1,1,1,\n",
    "    1,1,1,1,\n",
    "    1,1,1,1,\n",
    "    1,1,1,1,\n",
    "    0,1,1,1,\n",
    "    1,1,1,1,\n",
    "    1,0,0,1,\n",
    "    1,1,1,1,\n",
    "    0,1,1,1,\n",
    "    1,1,0,1,\n",
    "    1,1,1,1,\n",
    "    1,0,1,1,\n",
    "    1,1,1,1,\n",
    "    1,1,1,0,\n",
    "    1,0,1,1,\n",
    "    1,1,1,1,\n",
    "    1,1,1,1,\n",
    "    1,0,1,1,\n",
    "    1,0,0,1,\n",
    "    1,1,0,1,\n",
    "    1,1,1,1,\n",
    "    1,1,1,0,\n",
    "    0,1,1,0,\n",
    "    0,1,1,1,\n",
    "    1,0,1,1,\n",
    "    1,1,1,1,\n",
    "    1,1,1,0,\n",
    "    1,1,1,1,\n",
    "    1,1,1,1,\n",
    "    1,1,0,1,\n",
    "    1,0,1,0,\n",
    "    0,1,0,1,\n",
    "    1,1,1,1,\n",
    "    1,1,1,1,\n",
    "    1,1,1,0,\n",
    "    1,1,1,1,\n",
    "    1,1,0,1,\n",
    "    0,1,1,0,\n",
    "    0,0,1,0,\n",
    "    1,0,1,1,\n",
    "    1,0,1,1,\n",
    "    1,0,1,1,\n",
    "    1,0,1,1,\n",
    "    0,1,1   \n",
    "])\n",
    "avp_df['alc_resname_08'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode drugs involved 0 = no, 1 = yes\n",
    "avp_df['drugsname']=avp_df['drugsname'].replace([\n",
    "    'No (drugs not involved)', \n",
    "    'Not Reported', \n",
    "    'Reported as Unknown',\n",
    "    'Yes (drugs involved)'\n",
    "],[0,0,0,1])\n",
    "avp_df['drugsname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode transfer to hospital 0 = no 1 = yes\n",
    "avp_df['hospitalname']=avp_df['hospitalname'].replace([\n",
    "    'EMS Ground', \n",
    "    'Not Transported', \n",
    "    'Other', \n",
    "    'EMS Air',\n",
    "    'EMS Unknown Mode', \n",
    "    'Reported as Unknown',\n",
    "    'Transported  Unknown Source', \n",
    "    'Not Reported', \n",
    "    'Law Enforcement',\n",
    "    'Not Transported for Treatment'\n",
    "],[1,0,1,1,1,0,1,0,1,0])\n",
    "avp_df['hospitalname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avp_df['locationname'].unique()\n",
    "# NOT USEFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avp_df['sex_imname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode sex 0 = female, 1 = male : Assign not reported as male, unknown as female\n",
    "avp_df['sex_imname']=avp_df['sex_imname'].replace([\n",
    "    'Female', \n",
    "    'Male', \n",
    "    'Reported as Unknown', \n",
    "    'Not Reported'\n",
    "],[0,1,0,1])\n",
    "\n",
    "avp_df['sex_imname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode person level of injury\n",
    "avp_df['injsev_imname'] = avp_df['injsev_imname'].replace([\n",
    "    'Suspected Serious Injury (A)', \n",
    "    'No Apparent Injury (O)',\n",
    "    'Possible Injury (C)', \n",
    "    'Unknown/Not Reported',\n",
    "    'Suspected Minor Injury (B)',\n",
    "    'Fatal Injury (K)',\n",
    "    'Injured, Severity Unknown', \n",
    "    'Died Prior to Crash*'\n",
    "],[\n",
    "    'serious',\n",
    "    'none',\n",
    "    'minor',\n",
    "    'none',\n",
    "    'minor',\n",
    "    'fatal',\n",
    "    'minor',\n",
    "    'fatal'\n",
    " ])\n",
    "avp_df['injsev_imname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode personal alcohol use\n",
    "avp_df['peralch_imname']=avp_df['peralch_imname'].replace([\n",
    "    'No (Alcohol Not Involved)',\n",
    "    'Yes (Alcohol Involved)'\n",
    "],[0,1])\n",
    "avp_df['peralch_imname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avp_df['seat_imname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avp_df['seat_imname']=avp_df['seat_imname'].replace([\n",
    "    'Front Seat, Left Side', \n",
    "    \n",
    "    'Front Seat, Right Side',\n",
    "    'Front Seat, Middle',\n",
    "    'Front Seat, Unknown',\n",
    "    'Front Seat, Other', \n",
    "    'Not Reported',\n",
    "    'Reported as Unknown', \n",
    "    \n",
    "    'Second Seat, Left Side', \n",
    "    'Second Seat, Middle',\n",
    "    'Second Seat, Right Side', \n",
    "    'Second Seat, Unknown', \n",
    "    'Second Seat, Other',\n",
    "    \n",
    "    'Third Seat, Left Side',\n",
    "    'Third Seat, Middle', \n",
    "    'Third Seat, Right Side', \n",
    "    'Third Seat, Unknown', \n",
    "    'Third Seat, Other',\n",
    "    'Fourth Seat, Left Side',\n",
    "    'Fourth Seat, Right Side', \n",
    "    'Fourth Seat, Middle',\n",
    "    'Fourth Seat, Other',\n",
    "    \n",
    "    'Riding on Exterior of Vehicle', \n",
    "    'Appended to a Motor Vehicle for Motion',\n",
    "    \n",
    "    'Other Passenger in enclosed passenger or cargo area',\n",
    "    'Sleeper Section of Cab (Truck)',\n",
    "    'Other Passenger in passenger or cargo area, unknown whether or not enclosed',\n",
    "    'Other Passenger in unenclosed passenger or cargo area',\n",
    "    \n",
    "    'Trailing Unit',\n",
    "    \n",
    "],[\n",
    "    'Driver',\n",
    "    \n",
    "    'Front_passenger',\n",
    "    'Front_passenger',\n",
    "    'Front_passenger',\n",
    "    'Front_passenger',\n",
    "    'Front_passenger',\n",
    "    'Front_passenger',\n",
    "    \n",
    "    'Second_row',\n",
    "    'Second_row',\n",
    "    'Second_row',\n",
    "    'Second_row',\n",
    "    'Second_row',\n",
    "    \n",
    "    'Third_or_4 Row',\n",
    "    'Third_or_4 Row',\n",
    "    'Third_or_4 Row',\n",
    "    'Third_or_4 Row',\n",
    "    'Third_or_4 Row',\n",
    "    'Third_or_4 Row',\n",
    "    'Third_or_4 Row',\n",
    "    'Third_or_4 Row',\n",
    "    'Third_or_4 Row',\n",
    "    \n",
    "    'Riding_outside',\n",
    "    'Riding_outside',\n",
    "    \n",
    "    'Cargo_area',\n",
    "    'Cargo_area',\n",
    "    'Cargo_area',\n",
    "    'Cargo_area',\n",
    "    \n",
    "    'Trailer'    \n",
    "])\n",
    "avp_df['seat_imname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avp_df['age_im_temp']=avp_df['age_im'].replace([997,998,999],[np.NaN,np.NaN,np.NaN])\n",
    "avp_df['age_im_temp'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode age - impute median age = 34 years for missing\n",
    "avp_df['age_im']=avp_df['age_im'].replace([998,999],[34,34])\n",
    "avp_df['age_im'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV SEMI CLEAN - NEEDS SOME FIELDS DROPPED - NOT THE FINAL SET FOR MACHINE LEARNING\n",
    "avp_df.to_csv('all_gas_no_brakes_semiclean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT UPDATED BELOW THIS POINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL PROJECT MACHINE LEARNING CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONNECT DATA TO DATABASE\n",
    "crash_df = pd.read_csv(\"Resources/crash.csv\")\n",
    "crash_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESS THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique catagorical \n",
    "crash_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at XXXX value counts for binning\n",
    "XXXX_counts = application_df.XXXX.value_counts()\n",
    "#  How many XXXX counts are greater than X?\n",
    "XXXX_counts[XXXX_counts>X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  How many XXXX counts are less than or equal to X?\n",
    "XXXX_counts[XXXX_counts <= X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the value counts of XXXX\n",
    "XXXX_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which values to replace if counts are less than or equal to X.\n",
    "replace_crash = list(XXXX_counts[XXXX_counts <= X].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for crash in replace_crash:\n",
    "    crash_df.XXXX = crash_df.XXXX.replace(app,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "crash_df.XXXX.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable lists\n",
    "crash_cat = crash_df.dtypes[crash_df.dtypes == \"object\"].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(crash_df[crash_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(crash_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "crash_df = crash_df.merge(encode_df,left_index=True, right_index=True)\n",
    "crash_df = crash_df.drop(crash_cat,1)\n",
    "crash_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = crash_df[\"YVALUE\"].values\n",
    "X = crash_df.drop([\"YVALUE\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  200\n",
    "hidden_nodes_layer2 = 30\n",
    "hidden_nodes_layer3 = 10\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"sigmoid\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"sigmoid\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import checkpoint dependencies\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"crash_checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"crash_checkpoints/weights.{epoch:02d}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights every epoch\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"Crash.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
